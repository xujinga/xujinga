<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[word转pdf实现在线预览]]></title>
    <url>%2F2019%2F03%2F29%2Fword%E8%BD%ACpdf%E5%AE%9E%E7%8E%B0%E5%9C%A8%E7%BA%BF%E9%A2%84%E8%A7%88%2F</url>
    <content type="text"><![CDATA[这几天在做的一个项目里面有个需求，一些文件需要在前端嵌入到页面预览，但是服务器存的文件有word,有pdf,前台没法处理word文件，就需要后台把word转成pdf输出给前台展示。我在网上搜了一下，有很多种方法，我这边使用的是openOffice的服务来做的转换。 1.下载安装openOffice进入OpenOffice下载对应版本的openOffice,并启动服务 win 启动方法在 program 目录下 双击soffice.exe linux 启动方法临时启动/opt/openoffice4/program/soffice -headless -accept=&quot;socket,host=127.0.0.1,port=2002;urp;&quot; -nofirststartwizard &amp;永久启动nohup /opt/openoffice4/program/soffice -headless -accept=&quot;socket,host=127.0.0.1,port=2002;urp;&quot; -nofirststartwizard &amp; 2.封装工具类安装jar包123456789101112131415161718192021222324252627282930&lt;dependency&gt; &lt;groupId&gt;org.openoffice&lt;/groupId&gt; &lt;artifactId&gt;jurt&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.openoffice&lt;/groupId&gt; &lt;artifactId&gt;ridl&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.openoffice&lt;/groupId&gt; &lt;artifactId&gt;juh&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.openoffice&lt;/groupId&gt; &lt;artifactId&gt;unoil&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.openoffice&lt;/groupId&gt; &lt;artifactId&gt;unoil&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.artofsolving&lt;/groupId&gt; &lt;artifactId&gt;jodconverter&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt; 注意：jodconverter 2.2.1的版本不支持docx 2.2.2版本的中央库没有，文末会分享给大家 编写工具类1234567891011121314151617181920212223242526272829303132public class Word2Pdf &#123; // 将word格式的文件转换为pdf格式 //调用方法，传入原文档路径和目标文档路径即可完成转换 public static void Word2Pdf(String srcPath, String desPath) throws IOException &#123; // 源文件目录 File inputFile = new File(srcPath); if (!inputFile.exists()) &#123; log.error("源文件不存在"); return; &#125; // 输出文件目录 File outputFile = new File(desPath); if (!outputFile.getParentFile().exists()) &#123; outputFile.getParentFile().exists(); &#125; // 连接openoffice服务 OpenOfficeConnection connection = new SocketOpenOfficeConnection( "127.0.0.1", 8100); connection.connect(); log.debug("连接office服务"); // 转换word到pdf DocumentConverter converter = new OpenOfficeDocumentConverter( connection); converter.convert(inputFile, outputFile); // 关闭连接 connection.disconnect(); log.debug("转换完成"); &#125;&#125; 3.乱码问题解决乱码原因英文系统的Linux 内字体缺少，而对应需要转换的word中字体有多种不同类型字体，转换时无法对应，文末分享相关字体给大家 乱码解决 把字体文件夹放入到 /usr/share/fonts 刷新缓存：fc-cache 点击百度云获取字体和jar包 提取码:q4yh]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用七牛云做图片上传]]></title>
    <url>%2F2019%2F03%2F27%2F%E4%BD%BF%E7%94%A8%E4%B8%83%E7%89%9B%E4%BA%91%E5%81%9A%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[1.如何使用七牛云？注册登录不多说，点击七牛云进行注册登录。 添加新的对象存储空间 我这里添加的存储空间交photo 记录一些后面用到的重要参数进入刚刚创建的存储空间–内容管理，记住外链默认域名 点击我的–个人中心–密钥管理，记住AK SK 2.后台使用七牛云上传图片pox引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.qiniu&lt;/groupId&gt; &lt;artifactId&gt;qiniu-java-sdk&lt;/artifactId&gt; &lt;version&gt;7.1.1&lt;/version&gt; &lt;/dependency&gt; 编写七牛云工具类根据自己的需求改写，这种是前端调用返回图片链接的方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class QiniuCloudUtil &#123; // 设置需要操作的账号的AK和SK private static final String ACCESS_KEY = "填写刚刚记下的AK"; private static final String SECRET_KEY = "填写刚刚记下的SK"; // 要上传的空间 private static final String bucketname = "自己创建的存储空间名字"; // 密钥 private static final Auth auth = Auth.create(ACCESS_KEY, SECRET_KEY); //存储位置 private static final String DOMAIN = "刚刚记录的外链"; //private static final String style = "自定义的图片样式"; public String getUpToken() &#123; return auth.uploadToken(bucketname, null, 3600, new StringMap().put("insertOnly", 1)); &#125; //base64方式上传 public String put64image(byte[] base64, String key) throws Exception &#123; String file64 = Base64.encodeToString(base64, 0); Integer l = base64.length; String url = "http://upload.qiniu.com/putb64/" + l + "/key/" + UrlSafeBase64.encodeToString(key); //非华东空间需要根据注意事项 1 修改上传域名 RequestBody rb = RequestBody.create(null, file64); Request request = new Request.Builder(). url(url). addHeader("Content-Type", "application/octet-stream") .addHeader("Authorization", "UpToken " + getUpToken()) .post(rb).build(); //System.out.println(request.headers()); OkHttpClient client = new OkHttpClient(); okhttp3.Response response = client.newCall(request).execute(); //sSystem.out.println(response); //如果不需要添加图片样式，使用以下方式 if (response.code() == 200) &#123; return DOMAIN + "/" + key; &#125; else &#123; throw new RuntimeException(response.message()); &#125; //return DOMAIN + key + "?" + style; &#125;&#125; 编写上传接口给前端调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class UploadController &#123; //允许上传的图片类型 private final static List&lt;String&gt; ALLOW_EXT = Arrays.asList("jpg", "jpeg", "gif", "png", "bmp"); @PostMapping(value = "/uploadImg") @ApiOperation("图片上传") public String uploadImg(@RequestParam(value = "image") MultipartFile image) &#123; if (image.isEmpty()) &#123; return RequestResult.err("文件为空，请重新上传"); &#125; String extension = getExtension(image.getContentType()); if (extension == null || !ALLOW_EXT.contains(extension)) &#123; return RequestResult.err("不支持该文件类型"); &#125; try &#123; byte[] bytes = image.getBytes(); String imageName = UUID.randomUUID().toString(); QiniuCloudUtil qiniuUtil = new QiniuCloudUtil(); try &#123; //使用base64方式上传到七牛云 String url = qiniuUtil.put64image(bytes, imageName); return RequestResult.success("url", url); &#125; catch (Exception e) &#123; e.printStackTrace(); return RequestResult.err(e.getMessage()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); return RequestResult.err(e.getMessage()); &#125; &#125; private String getExtension(String contentType) &#123; if (StringUtils.isNotBlank(contentType)) &#123; //通过imgContentType判断 int index = contentType.lastIndexOf("/"); if (index &lt; 0 || index + 1 &gt; contentType.length()) &#123; return null; &#125; else &#123; return contentType.substring(index + 1).toLowerCase(); &#125; &#125; return null; &#125;&#125; 3.postMan模拟前端调用接口返回上传后图片的链接 访问链接，就能看见刚刚上传的图片 打开七牛云刚刚自己创建的存储空间，点卡内容管理，也能看见自己刚刚上传的图片 这样的话使用七牛云做简单的图片上传功能就完成了，有一些进阶操作可以参考七牛云开发文档。]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hutool导出excel]]></title>
    <url>%2F2019%2F03%2F06%2F%E4%BD%BF%E7%94%A8hutool%E5%AF%BC%E5%87%BAexcel%2F</url>
    <content type="text"><![CDATA[Hutool是一个Java工具包，里面有很多非常方便的工具类，之前我们做一个excel导出特别麻烦，逻辑也非常绕，用Hutool几行代码就搞定了，非常方便。 1.安装maven方式在项目的pom.xml的dependencies中加入以下内容1234567891011121314151617&lt;!--hutool--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--excel相关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;xerces&lt;/groupId&gt; &lt;artifactId&gt;xercesImpl&lt;/artifactId&gt; &lt;version&gt;2.11.0&lt;/version&gt; &lt;/dependency&gt; 说明 poi-ooxml 版本需高于 3.17（别问我3.8版本为啥不行，因为3.17 &gt; 3.8 ） xercesImpl版本高于2.11.0 2.封装自己使用的工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ExcelUtils &#123; /** * 写出Bean数据 * * @param response * @param list 输出到excel的列表 * @param map excel 列和 类的字段对应关系 如 key: name --&gt; value:名字 * @param title excel 标题 */ public static void exportExcel(HttpServletResponse response, List list, Map&lt;String, String&gt; map, String title) throws IOException &#123; //设置输出头 response.setHeader("Content-Disposition", "attachment;fileName=" + new String((new SimpleDateFormat("yyyyMMddHHmmss").format(new Date()) + ".xlsx").getBytes("UTF-8"))); // 通过工具类创建writer ExcelWriter writer = ExcelUtil.getWriter(true); //自定义标题别名 Set&lt;Map.Entry&lt;String, String&gt;&gt; entries = map.entrySet(); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = entries.iterator(); while (iterator.hasNext()) &#123; Map.Entry&lt;String, String&gt; next = iterator.next(); writer.addHeaderAlias(next.getKey(), next.getValue()); &#125; // 合并单元格后的标题行，使用默认标题样式 writer.merge(map.size() - 1, title); // 一次性写出内容，使用默认样式，强制输出标题 writer.write(list, true); //out为OutputStream，需要写出到的目标流 writer.flush(response.getOutputStream()); // 关闭writer，释放内存 writer.close(); &#125; /** * 写出map数据 * * @param response * @param list 输出到excel的列表 * @param title excel 标题 */ public static void exportExcel(HttpServletResponse response, List&lt;Map&lt;String, Object&gt;&gt; list, String title) throws IOException &#123; //设置输出头 response.setHeader("Content-Disposition", "attachment;fileName=" + new String((new SimpleDateFormat("yyyyMMddHHmmss").format(new Date()) + ".xlsx").getBytes("UTF-8"))); // 通过工具类创建writer ExcelWriter writer = ExcelUtil.getWriter(true); // 合并单元格后的标题行，使用默认标题样式 writer.merge(list.size() - 1, title); // 一次性写出内容，使用默认样式，强制输出标题 writer.write(list, true); //out为OutputStream，需要写出到的目标流 writer.flush(response.getOutputStream()); // 关闭writer，释放内存 writer.close(); &#125; 第一个方法的list 里面装的是bean，map装的是bean中英文字段和中文汉字的对应关系。第二个方法list装的是map map里面是类似map.put(“姓名”,”张三”)，map.put(“年龄”,”14”) 几行代码就搞定了，是不是特别简单。我这个是以流的方式给前台，浏览器访问就直接下载了，还有写入文件中的方法，具体的去hutool官方文档，里面有详细介绍]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[客服系统二]]></title>
    <url>%2F2018%2F11%2F02%2F%E5%AE%A2%E6%9C%8D%E7%B3%BB%E7%BB%9F%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[一、netty配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class NettyConfig&#123; private static final Logger logger = LoggerFactory.getLogger(NettyConfigImpl.class); private final ServerBootstrap bootstrap = new ServerBootstrap(); private EventLoopGroup parentGroup = new NioEventLoopGroup(); private EventLoopGroup childGroup = new NioEventLoopGroup(); private Class channelClass = NioServerSocketChannel.class; public void setHandler() &#123; validate(); bootstrap.group(parentGroup, childGroup); bootstrap.channel(channelClass); bootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); //自带的粘包拆包 pipeline.addFirst(new LengthFieldBasedFrameDecoder(1024*1024*10,3,4,0,0,false)); //解码器 pipeline.addLast("ProtocolDecoder", new ProtocolDecoder()); //编码器 pipeline.addLast("ProtocolEncoder", new ProtocolEncoder()); //心跳六秒检测一次 pipeline.addLast("IdleStateHandler", new IdleStateHandler(6, 0, 0)); //业务逻辑处理 pipeline.addLast("AcceptorHandler", new AcceptorHandler()); &#125; &#125;).option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); &#125; public void start(int port, boolean sync) &#123; ChannelFuture future = null; try &#123; future = bootstrap.bind(port).sync(); logger.info("服务器启动成功 监听端口(" + port + ")"); if (sync) &#123; future.channel().closeFuture().sync(); &#125; else &#123; future.channel().closeFuture(); &#125; logger.info("服务器关闭"); &#125; catch (InterruptedException e) &#123; logger.warn("Netty绑定异常", e); &#125; finally &#123; parentGroup.shutdownGracefully(); childGroup.shutdownGracefully(); &#125; &#125;&#125; 二、定义协议头1234567891011121314151617/** * 传输层协议头. * __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ * | | | | | | * 1 1 1 4 Uncertainty * |__ __ __ __|__ __ __ __|__ __ __ __|__ __ __ __ __|__ __ __ __ __ __ __ __ __| * | | | | | | * Sign Type Status Body Length Body Content * |__ __ __ __|__ __ __ __|__ __ __ __|__ __ __ __ __|__ __ __ __ __ __ __ __ __| * &lt;p&gt; * 协议头7个字节定长 * Sign // 消息标志，请求／响应／通知，byte类型 * Type // 消息类型，登录／发送消息等，byte类型 * Status // 响应状态，成功／失败，byte类型 * BodyLength // 协议体长度，int类型 * */ 三、定义传输载体1234567891011121314public class MessageHolder &#123; // 消息标志 private byte sign; // 消息类型 private byte type; // 响应状态 private byte status; // Json消息体 private String body; // 接收到消息的通道 private Channel channel; //省略get set &#125; 四、定义编解码器编码器 123456789101112131415161718192021public class ProtocolEncoder extends MessageToByteEncoder&lt;MessageHolder&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, MessageHolder msg, ByteBuf out) throws Exception &#123; String body = msg.getBody(); //body = filterEmoji(body); if (body == null) &#123; throw new NullParamsException("body == null"); &#125; // 编码 byte[] bytes = body.getBytes("utf-8"); /*if (msg.getType() != 22) &#123; System.err.println(msg); &#125;*/ out.writeByte(msg.getSign()) .writeByte(msg.getType()) .writeByte(msg.getStatus()) .writeInt(bytes.length) .writeBytes(bytes); &#125;&#125; 解码器 1234567891011121314151617181920212223242526272829303132333435363738394041public class ProtocolDecoder extends ByteToMessageDecoder &#123; private static final Logger logger = LoggerFactory.getLogger(ProtocolDecoder.class); @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; if (in.readableBytes() &lt; ProtocolHeader.HEADER_LENGTH) &#123; // 数据包长度小于协议头长度 logger.error("数据包长度小于协议头长度"); return; &#125; //标记索引位置 in.markReaderIndex(); // 开始解码 byte sign = in.readByte(); byte type = in.readByte(); byte status = in.readByte(); // 确认消息体长度 int bodyLength = in.readInt(); if (in.readableBytes() != bodyLength) &#123; // 消息体长度不一致 logger.error("消息体长度不一致"); //还原索引位置 in.resetReaderIndex(); return; &#125; byte[] bytes = new byte[bodyLength]; in.readBytes(bytes); MessageHolder messageHolder = new MessageHolder(); messageHolder.setSign(sign); messageHolder.setType(type); messageHolder.setStatus(status); messageHolder.setBody(new String(bytes, "utf-8")); out.add(messageHolder); &#125;&#125; 五、定义业务逻辑处理的handler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class AcceptorHandler extends ChannelInboundHandlerAdapter &#123; private static final Logger logger = LoggerFactory.getLogger(AcceptorHandler.class); private final BlockingQueue&lt;MessageHolder&gt; taskQueue; public AcceptorHandler() &#123; taskQueue = TaskQueue.getQueue(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof MessageHolder) &#123; MessageHolder messageHolder = (MessageHolder) msg; // 指定Channel messageHolder.setChannel(ctx.channel()); //任务分发 dispatch(messageHolder); &#125; else &#123; throw new IllegalArgumentException("msg is not instance of MessageHolder"); &#125; &#125; public static void dispatch(MessageHolder messageHolder) &#123; try &#123; if (messageHolder.getSign() != ProtocolHeader.REQUEST) &#123; // 请求错误 response(messageHolder.getChannel(), messageHolder.getType(), ProtocolHeader.REQUEST_ERROR); log.error("请求错误"); return; &#125; switch (messageHolder.getType()) &#123; // 登录 case ProtocolHeader.LOGIN: Account aLogin = JSON.parseObject(messageHolder.getBody(), Account.class); new Login(aLogin, messageHolder.getChannel()).deal(); break; // 登出 case ProtocolHeader.LOGOUT: Account aLogout = JSON.parseObject(messageHolder.getBody(), Account.class); new Logout(aLogout, messageHolder.getChannel()).deal(); break; // 微信个人消息 case ProtocolHeader.WECHAT_PERSON_MESSAGE: try &#123; Message wechatMessage = JSON.parseObject(messageHolder.getBody(), Message.class); new WechatPersonMessage(wechatMessage, messageHolder.getChannel()).deal(); &#125;catch (Exception e)&#123; log.error(messageHolder.getBody()); &#125; break; // 断线重连 case ProtocolHeader.RECONN: Account reconn = JSON.parseObject(messageHolder.getBody(), Account.class); new Reconn(reconn, messageHolder.getChannel()).deal(); break; // 请求错误 default: response(messageHolder.getChannel(), messageHolder.getType(), ProtocolHeader.REQUEST_ERROR); break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); response(messageHolder.getChannel(), messageHolder.getType(), ProtocolHeader.SERVER_ERROR); &#125; // 释放buffer ReferenceCountUtil.release(messageHolder); &#125;&#125; 六、定义心跳handler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class HeartbeatHandler extends ChannelInboundHandlerAdapter &#123; private static final Logger logger = LoggerFactory.getLogger(HeartbeatHandler.class); public static AtomicBoolean isLogout = new AtomicBoolean(false); private Channel channel; private String username; // 丢失的心跳数 private static int counter = 0; public HeartbeatHandler(Channel channel) &#123; this.channel = channel; &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; if (username == null) &#123; username = ConnPool.query(channel); &#125; // 心跳丢失 counter++; if (counter &gt; 4) &#123; // 心跳丢失数达到5个，主动断开连接 ctx.channel().close(); &#125; logger.info(username + " 丢失" + counter + "个心跳包"); &#125; &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; ConnPool.remove(username); if (isLogout.get()) &#123; isLogout.set(false); logger.info(username + " 退出登录"); &#125; else &#123; logger.info(username + " 与服务器断开连接"); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof MessageHolder) &#123; MessageHolder messageHolder = (MessageHolder) msg; if (messageHolder.getType() == ProtocolHeader.HEARTBEAT) &#123; if (username == null) &#123; username = ConnPool.query(channel); &#125; // 心跳丢失清零 counter = 0; //logger.info(username + " 收到心跳包"); Set&lt;String&gt; keys = RedisUtil.keys("im_" + username + "_*"); Map&lt;String, Integer&gt; map = new HashMap(); map.put("receptionNum", keys.size()); sendResponse(channel, ProtocolHeader.SUCCESS, ProtocolHeader.RECEPTION_NUM, JSON.toJSONString(map)); ReferenceCountUtil.release(msg); &#125; else &#123; ctx.fireChannelRead(msg); &#125; &#125; &#125; /** * 服务器响应 */ @SuppressWarnings("all") private void sendResponse(Channel channel, byte status, byte type, String body) &#123; MessageHolder messageHolder = new MessageHolder(); messageHolder.setSign(ProtocolHeader.RESPONSE); messageHolder.setType(type); messageHolder.setStatus(status); messageHolder.setBody(body); channel.writeAndFlush(messageHolder); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; sendResponse(ctx.channel(), ProtocolHeader.SERVER_ERROR, ProtocolHeader.EXCEPTION, "服务器异常"); logger.error(cause.getMessage()); &#125;&#125;]]></content>
      <categories>
        <category>客服系统</category>
      </categories>
      <tags>
        <tag>im</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用javaMail做异常提醒]]></title>
    <url>%2F2018%2F11%2F02%2F%E4%BD%BF%E7%94%A8javaMail%E5%81%9A%E5%BC%82%E5%B8%B8%E6%8F%90%E9%86%92%2F</url>
    <content type="text"><![CDATA[一、异常收集拦截所有前台得到的异常 并写入到.txt文件中1234567891011121314151617181920212223242526272829303132333435363738394041@Slf4j@ResponseBody@ControllerAdvicepublic class GlobalExceptionHandler &#123; /** * 所有异常报错 * * @param request * @param exception * @return * @throws Exception */ @ExceptionHandler(value = Exception.class) public String allExceptionHandler(HttpServletRequest request, Exception exception) throws Exception &#123; //将异常写入服务器中 String today = DateUtil.today(); String path = ResourceFileUtil.getPath("exception"); File parentDir = new File(path); if (!parentDir.exists()) &#123; parentDir.mkdirs(); &#125; FileWriter writer = null; PrintWriter printWriter = null; try &#123; String fileName = path + today + ".txt"; writer = new FileWriter(fileName, true); printWriter = new PrintWriter(writer, true); //异常的信息和原因一致 视为一个异常，同一种异常只写一次就行了 String key = "exception_" + today + "_" + exception.getMessage() + "_" + exception.getCause(); if (RedisUtil.setIfAbsent(key, true, 24, TimeUnit.HOURS)) &#123; exception.printStackTrace(printWriter); exception.printStackTrace(); &#125; &#125; finally &#123; writer.close(); printWriter.close(); &#125; return RequestResult.err("服务器忙"); &#125;&#125; 二、集成javaMail pom.xml 12345&lt;!-- 支持发送邮件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt; 编写工具类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class EmailUtil &#123; private static String smtp = "smtp";//协议 private static String host = "smtp.qq.com";//使用什么服务器发送 aliyun qq 163等 private static String sendPort = "465";//发送的端口号 默认是25 一般服务器 厂商把25端口禁用了 private static String userName = "****@qq.com";//账号 private static String userPwd = "****";//授权码 private static String nickNmae = "****";//发送是的昵称 /** * 邮件发送的方法 * * @param to 收件人 * @param subject 主题 * @param content 内容 * @return 成功或失败 */ public static boolean send(String to, String subject, String content, String fileName) &#123; // 第一步：创建Session Properties props = new Properties(); // 指定邮件的传输协议，smtp(Simple Mail Transfer Protocol 简单的邮件传输协议) props.put("mail.smtp.auth", "true"); props.put("mail.transport.protocol", smtp); // 指定邮件发送服务器服务器 "smtp.qq.com" props.put("mail.smtp.host", host); props.put("mail.smtp.starttls.enable", "true"); props.put("mail.smtp.socketFactory.fallback", "false"); props.put("mail.smtp.socketFactory.port", sendPort); props.put("mail.smtp.socketFactory.class", "javax.net.ssl.SSLSocketFactory"); props.put("mail.smtp.port", sendPort); Session session = Session.getDefaultInstance(props); // 开启调试模式 session.setDebug(true); try &#123; // 第二步：获取邮件发送对象 Transport transport = session.getTransport(); // 连接邮件服务器，链接您的163、sina邮箱，用户名（不带@163.com，登录邮箱的邮箱账号，不是邮箱地址）、密码 transport.connect(userName, userPwd); Address toAddress = new InternetAddress(to); // 第三步：创建邮件消息体 MimeMessage message = new MimeMessage(session); message.setFrom(new InternetAddress(nickNmae + " &lt;" + userName + "&gt;")); // 邮件的主题 message.setSubject(subject); //收件人 message.addRecipient(Message.RecipientType.TO, toAddress); // 邮件的内容 Multipart mp = new MimeMultipart(); MimeBodyPart mbpContent = new MimeBodyPart(); mbpContent.setText(content); mp.addBodyPart(mbpContent); /* 往邮件中添加附件 */ File file = new File(fileName); if (file.exists()) &#123; MimeBodyPart mbpFile = new MimeBodyPart(); FileDataSource fds = new FileDataSource(fileName); mbpFile.setDataHandler(new DataHandler(fds)); mbpFile.setFileName(fds.getName()); mp.addBodyPart(mbpFile); &#125; message.setContent(mp); // 邮件发送时间 message.setSentDate(new Date()); // 第四步：发送邮件 // 第一个参数：邮件的消息体 // 第二个参数：邮件的接收人，多个接收人用逗号隔开（test1@163.com,test2@sina.com） transport.sendMessage(message, InternetAddress.parse(to)); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return false; &#125;&#125; 三、定时发送邮件使用定时任务每天上午九点向开发者邮箱发送邮件12345678910111213141516171819202122232425@Component@EnableSchedulingpublic class MobileTask &#123; /** * 每日上午九点执行 * 发送异常邮件 */ @Scheduled(cron = "0 0 9 * * ?") // 每日上午九点执行 public void autoSendExceptionEmail() &#123; //发送邮件 String yesterday = DateUtil.yesterday().toString("yyyy-MM-dd"); String path = ResourceFileUtil.getPath("exception"); String fileName = path + yesterday + ".txt"; EmailUtil.send("****@qq.com", yesterday + "异常提醒邮件", yesterday + "异常附件，请查收(若无附件说明昨日没有产生异常)", fileName); //删除昨日所有的键 String keyPatten = "exception_" + yesterday + "*"; Set&lt;String&gt; exceptionKeys = RedisUtil.keys(keyPatten); Iterator&lt;String&gt; iterator = exceptionKeys.iterator(); while (iterator.hasNext()) &#123; String next = iterator.next(); RedisUtil.del(next); &#125; &#125;&#125;]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用solr优化商品搜索效率]]></title>
    <url>%2F2018%2F11%2F02%2F%E4%BD%BF%E7%94%A8solr%E4%BC%98%E5%8C%96%E5%95%86%E5%93%81%E6%90%9C%E7%B4%A2%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[一、前言我们的一个电商项目，之前前台使用的搜索接口是通过商品名称或者编号去数据库检索，返回给前台一系列符合的商品集合，能基本完成搜索的功能，但是当并发量高的的时候会对数据库造成不小的压力，而且查询速率也不是很好，所以我这周接到了这个任务，优化这个搜索功能，尝试使用solr去解决。 二、solr介绍什么是solr Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。 为什么使用solr solr是将整个索引操作功能封装好了的搜索引擎系统(企业级搜索引擎产品) solr可以部署到单独的服务器上(WEB服务)，它可以提供服务，我们的业务系统就只要发送请求，接收响应即可，降低了业务系统的负载 solr部署在专门的服务器上，它的索引库就不会受业务系统服务器存储空间的限制 solr支持分布式集群，索引服务的容量和能力可以线性扩展 solr的工作机制 solr就是在lucene工具包的基础之上进行了封装，而且是以web服务的形式对外提供索引功能 业务系统需要使用到索引的功能（建索引，查索引）时，只要发出http请求，并将返回数据进行解析即可 Solr 是Apache下的一个顶级开源项目，采用Java开发，它是基于Lucene的全文搜索服务器。Solr提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展，并对索引、搜索性能进行了优化。 Solr可以独立运行，运行在Jetty、Tomcat等这些Servlet容器中，Solr 索引的实现方法很简单，用 POST 方法向 Solr 服务器发送一个描述 Field 及其内容的 XML 文档，Solr根据xml文档添加、删除、更新索引 。Solr 搜索只需要发送 HTTP GET 请求，然后对 Solr 返回Xml、json等格式的查询结果进行解析，组织页面布局。Solr不提供构建UI的功能，Solr提供了一个管理界面，通过管理界面可以查询Solr的配置和运行情况。 三、solr的使用安装Apache Solr下载最新版本的Apache Solr 点击进行下载，下载进行解压，目录结构如图所示: 进入bin目录，使用命令行输入solr start在浏览器打开 http://localhost:8983/进入solr 管理界面这样solr 的安装就完成啦 solr 启动、停止、重启命令solr start -p 端口号solr stop -allsolr restart -p 端口号 配置Apache Solr创建core实例 core简介：简单说core就是solr的一个实例，一个solr服务下可以有多个core，每个core下都有自己的索引库和与之相应的配置文件，所以在操作solr创建索引之前要创建一个core，因为索引都存在core下面 core创建：core的创建方式有很多种一下列出两种比较方便的。 在bin目录下执行solr create –c name，创建一个core，默认创建出来的位置如下图 第二种方式是直接使用AdminUI页面创建一个core，如下图使用第二种方式会出现一个问题需要在将目录\solr-7.5.0\server\solr\configsets\_default目录下的 conf 拷贝到刚刚新建的core下面 重启solr服务就好了 配置schema schema简介： schema是用来告诉solr如何建立索引的，他的配置围绕着一个schema配置文件，这个配置文件决定着solr如何建立索引，每个字段的数据类型，分词方式等，老版本的schema配置文件的名字叫做schema.xml他的配置方式就是手工编辑，但是现在新版本的schema配置文件的名字叫做managed-schema，他的配置方式不再是用手工编辑而是使用schemaAPI来配置，官方给出的解释是使用schemaAPI修改managed-schema内容后不需要重新加载core或者重启solr更适合在生产环境下维护，如果使用手工编辑的方式更改配置不进行重加载core有可能会造成配置丢失，配置文件所在的路径如下图：直接贴上我的代码吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;schema name=&quot;example-DIH-db&quot; version=&quot;1.6&quot;&gt; &lt;!--自己查询的一些数据--&gt; &lt;field name=&quot;id&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; required=&quot;true&quot; multiValued=&quot;false&quot; /&gt; &lt;field name=&quot;userId&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;spuNo&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;categoryId&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;name&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;type&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;labels&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;price&quot; type=&quot;double&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;fixedPrice&quot; type=&quot;double&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;minPrice&quot; type=&quot;double&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;maxPrice&quot; type=&quot;double&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;pics&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;initialSales&quot; type=&quot;int&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;realSales&quot; type=&quot;int&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;onSale&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;onSaleTime&quot; type=&quot;date&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;isMul&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;expressTempId&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;stock&quot; type=&quot;int&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;stockType&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;priority&quot; type=&quot;int&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;fatherCategoryId&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;fromLibId&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;vipPriceEnable&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;promotionType&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;createTime&quot; type=&quot;date&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;lastUpdateTime&quot; type=&quot;date&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;isDel&quot; type=&quot;boolean&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;!--solr自带的数据--&gt; &lt;field name=&quot;_version_&quot; type=&quot;long&quot; indexed=&quot;false&quot; stored=&quot;false&quot;/&gt; &lt;field name=&quot;text&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;false&quot; multiValued=&quot;true&quot;/&gt; &lt;field name=&quot;_root_&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;false&quot; docValues=&quot;false&quot; /&gt; &lt;!--主键--&gt; &lt;uniqueKey&gt;id&lt;/uniqueKey&gt; &lt;!--基本的一些数据类型 solr不支持数据库的bigDecimal 和tinyint 用double和boolean代替--&gt; &lt;fieldType name=&quot;string&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; /&gt; &lt;fieldType name=&quot;int&quot; class=&quot;solr.TrieIntField&quot; docValues=&quot;true&quot; precisionStep=&quot;0&quot; positionIncrementGap=&quot;0&quot;/&gt; &lt;fieldType name=&quot;long&quot; class=&quot;solr.TrieLongField&quot; docValues=&quot;true&quot; precisionStep=&quot;0&quot; positionIncrementGap=&quot;0&quot;/&gt; &lt;fieldType name=&quot;date&quot; class=&quot;solr.TrieDateField&quot; docValues=&quot;true&quot; precisionStep=&quot;0&quot; positionIncrementGap=&quot;0&quot;/&gt; &lt;fieldType name=&quot;double&quot; class=&quot;solr.TrieDoubleField&quot; docValues=&quot;true&quot; precisionStep=&quot;0&quot; positionIncrementGap=&quot;0&quot;/&gt; &lt;fieldType name=&quot;boolean&quot; class=&quot;solr.BoolField&quot; omitNorms=&quot;true&quot;/&gt; &lt;!-- ik分词器 --&gt; &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; useSmart=&quot;false&quot; conf=&quot;ik.conf&quot;/&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; useSmart=&quot;true&quot; conf=&quot;ik.conf&quot;/&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt; &lt;/fieldType&gt;&lt;/schema&gt; 配置IK Analyzer中文分词器先下载 IK Analyzer中文分词器架包及相关配置文件。 准备IK中文分词器环境 把IK中文分词器架包复制到solr项目的WEB-INF/lib目录下 把IK分词器相关配置文件复制到solr项目WEB-INF/classes/ 目录下 (没有自己新建) 配置solrconfig配置搜索建议，在solrconfig.xml找到suggest123456789101112131415161718192021222324252627282930&lt;searchComponent class=&quot;solr.SpellCheckComponent&quot; name=&quot;suggest&quot;&gt; &lt;str name=&quot;queryAnalyzerFieldType&quot;&gt;string&lt;/str&gt; &lt;lst name=&quot;spellchecker&quot;&gt; &lt;str name=&quot;name&quot;&gt;suggest&lt;/str&gt; &lt;str name=&quot;classname&quot;&gt;org.apache.solr.spelling.suggest.Suggester&lt;/str&gt; &lt;str name=&quot;lookupImpl&quot;&gt;org.apache.solr.spelling.suggest.tst.TSTLookup&lt;/str&gt; &lt;!--建议字段名--&gt; &lt;str name=&quot;field&quot;&gt;name&lt;/str&gt; &lt;!-- the indexed field to derive suggestions from --&gt; &lt;float name=&quot;threshold&quot;&gt;0.0001&lt;/float&gt; &lt;str name=&quot;spellcheckIndexDir&quot;&gt;spellchecker&lt;/str&gt; &lt;str name=&quot;comparatorClass&quot;&gt;freq&lt;/str&gt; &lt;str name=&quot;buildOnOptimize&quot;&gt;true&lt;/str&gt; &lt;!--&lt;str name=&quot;buildOnCommit&quot;&gt;true&lt;/str&gt;--&gt; &lt;/lst&gt; &lt;/searchComponent&gt; &lt;requestHandler class=&quot;org.apache.solr.handler.component.SearchHandler&quot; name=&quot;/suggest&quot;&gt; &lt;lst name=&quot;defaults&quot;&gt; &lt;str name=&quot;spellcheck&quot;&gt;true&lt;/str&gt; &lt;str name=&quot;spellcheck.dictionary&quot;&gt;suggest&lt;/str&gt; &lt;str name=&quot;spellcheck.onlyMorePopular&quot;&gt;true&lt;/str&gt; &lt;str name=&quot;spellcheck.extendedResults&quot;&gt;false&lt;/str&gt; &lt;str name=&quot;spellcheck.count&quot;&gt;10&lt;/str&gt; &lt;str name=&quot;spellcheck.collate&quot;&gt;true&lt;/str&gt; &lt;/lst&gt; &lt;arr name=&quot;components&quot;&gt; &lt;str&gt;suggest&lt;/str&gt; &lt;/arr&gt; &lt;/requestHandler&gt; 数据库数据导入 修改soreconfig.xml在soreconfig.xml的上面添加如下代码： 12345&lt;requestHandler name=&quot;/dataimport&quot; class=&quot;solr.DataImportHandler&quot;&gt; &lt;lst name=&quot;defaults&quot;&gt; &lt;str name=&quot;config&quot;&gt;db-data-config.xml&lt;/str&gt; &lt;/lst&gt; &lt;/requestHandler&gt; 在同级目录下创建data-config.xml文件，然后配置数据库相关属性注意：这里面配置的属性需要和上文中 schema中配置的一样 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;dataConfig&gt; &lt;dataSource type=&quot;JdbcDataSource&quot; driver=&quot;com.mysql.jdbc.Driver&quot; url=&quot;jdbc:mysql://127.0.0.1:3306/saas?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=false&quot; user=&quot;root&quot; password=&quot;123456&quot;/&gt; &lt;document&gt; &lt;entity dataSource=&quot;JdbcDataSource&quot; name=&quot;mall_product&quot; query=&quot;select mp.*,mo.promotionType from mall_product mp LEFT JOIN mall_promotion mo ON mp.id = mo.productId AND mo.`status` = 0 where mp.isDel = 0; &quot; pk=&quot;id&quot;&gt; &lt;field column=&quot;id&quot; name=&quot;id&quot;/&gt; &lt;field column=&quot;userId&quot; name=&quot;userId&quot;/&gt; &lt;field column=&quot;spuNo&quot; name=&quot;spuNo&quot;/&gt; &lt;field column=&quot;categoryId&quot; name=&quot;categoryId&quot;/&gt; &lt;field column=&quot;name&quot; name=&quot;name&quot;/&gt; &lt;field column=&quot;type&quot; name=&quot;type&quot;/&gt; &lt;field column=&quot;labels&quot; name=&quot;labels&quot;/&gt; &lt;field column=&quot;price&quot; name=&quot;price&quot;/&gt; &lt;field column=&quot;fixedPrice&quot; name=&quot;fixedPrice&quot;/&gt; &lt;field column=&quot;minPrice&quot; name=&quot;minPrice&quot;/&gt; &lt;field column=&quot;maxPrice&quot; name=&quot;maxPrice&quot;/&gt; &lt;field column=&quot;pics&quot; name=&quot;pics&quot;/&gt; &lt;field column=&quot;initialSales&quot; name=&quot;initialSales&quot;/&gt; &lt;field column=&quot;realSales&quot; name=&quot;realSales&quot;/&gt; &lt;field column=&quot;onSale&quot; name=&quot;onSale&quot;/&gt; &lt;field column=&quot;onSaleTime&quot; name=&quot;onSaleTime&quot;/&gt; &lt;field column=&quot;isMul&quot; name=&quot;isMul&quot;/&gt; &lt;field column=&quot;expressTempId&quot; name=&quot;expressTempId&quot;/&gt; &lt;field column=&quot;stock&quot; name=&quot;stock&quot;/&gt; &lt;field column=&quot;stockType&quot; name=&quot;stockType&quot;/&gt; &lt;field column=&quot;priority&quot; name=&quot;priority&quot;/&gt; &lt;field column=&quot;fatherCategoryId&quot; name=&quot;fatherCategoryId&quot;/&gt; &lt;field column=&quot;fromLibId&quot; name=&quot;fromLibId&quot;/&gt; &lt;field column=&quot;vipPriceEnable&quot; name=&quot;vipPriceEnable&quot;/&gt; &lt;field column=&quot;promotionType&quot; name=&quot;promotionType&quot;/&gt; &lt;field column=&quot;createTime&quot; name=&quot;createTime&quot;/&gt; &lt;field column=&quot;lastUpdateTime&quot; name=&quot;lastUpdateTime&quot;/&gt; &lt;field column=&quot;isDel&quot; name=&quot;isDel&quot;/&gt; &lt;/entity&gt; &lt;/document&gt;&lt;/dataConfig&gt; 拷贝jar拷贝solr-7.5.0\dist路径下的solr-dataimporthandler-7.5.0.jar，solr-dataimporthandler-extras-7.5.0.jar 到 solr-7.5.0\server\solr-webapp\webapp\WEB-INF\lib目录下同时拷贝mysql-connector-java-5.1.40.jar链接jar到该目录下 数据导入重启solr 进入管理页面然后就能看见你要的数据了 四、springboot集成solr 引入jar包 1234&lt;dependency&gt;&lt;groupId&gt;org.springframework.data&lt;/groupId&gt;&lt;artifactId&gt;spring-data-solr&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 1234spring: data: solr: host: http://127.0.0.1:8983/solr 相关代码 @Service public class ProductSolrServiceImpl implements ProductSolrService { @Resource private PromotionService promotionService; @Resource private SolrClient solrClient; @Override public String saveOrUpdate(Product product) { try { SolrInputDocument doc = new SolrInputDocument(); doc.setField("id", product.getId()); doc.setField("userId", product.getUserId()); doc.setField("spuNo", product.getSpuNo()); doc.setField("categoryId", product.getCategoryId()); doc.setField("name", product.getName()); doc.setField("type", product.getType()); doc.setField("labels", product.getLabels()); if (product.getPrice() != null) { doc.setField("price", product.getPrice().doubleValue()); } if (product.getFixedPrice() != null) { doc.setField("fixedPrice", product.getFixedPrice().doubleValue()); } if (product.getMinPrice() != null) { doc.setField("minPrice", product.getMinPrice().doubleValue()); } if (product.getMaxPrice() != null) { doc.setField("maxPrice", product.getMaxPrice().doubleValue()); } doc.setField("pics", product.getPics()); doc.setField("initialSales", product.getInitialSales()); doc.setField("realSales", product.getRealSales()); doc.setField("onSale", product.getOnSale()); doc.setField("onSaleTime", product.getOnSaleTime()); doc.setField("isMul", product.getIsMul()); doc.setField("expressTempId", product.getExpressTempId()); doc.setField("stock", product.getStock()); doc.setField("stockType", product.getStockType()); doc.setField("priority", product.getPriority()); doc.setField("fatherCategoryId", product.getFatherCategoryId()); doc.setField("fromLibId", product.getFromLibId()); doc.setField("vipPriceEnable", product.getVipPriceEnable()); doc.setField("createTime", product.getCreateTime()); doc.setField("lastUpdateTime", product.getLastUpdateTime()); doc.setField("isDel", false); Promotion promotion = promotionService.findByProductId(product.getId()); if (null != promotion) { doc.setField("promotionType", promotion.getPromotionType()); } solrClient.add("mall_product", doc); solrClient.commit("mall_product"); return "success"; } catch (Exception e) { e.printStackTrace(); } return "error"; } @Override public String delete(String id) { try { solrClient.deleteById("mall_product", id); solrClient.commit("mall_product"); return "success"; } catch (Exception e) { e.printStackTrace(); } return "error"; } @Override public String deleteAll() { try { solrClient.deleteByQuery("mall_product", "*:*"); solrClient.commit("mall_product"); return "success"; } catch (Exception e) { e.printStackTrace(); } return "error"; } @Override public String getById(String id) { try { SolrDocument document = solrClient.getById("mall_product", id); return document.toString(); } catch (Exception e) { e.printStackTrace(); } return null; } @Override public List&lt;ProductSolrEntity&gt; search(ProductSolrQuery productSolrQuery) { try { SolrQuery params = new SolrQuery(); //查询条件, 这里的 q 对应 下面图片标红的地方 params.setQuery("name:" + productSolrQuery.getName() + " OR " + "spuNo:" + productSolrQuery.getName()); //过滤条件 params.addFilterQuery("userId:" + productSolrQuery.getUserId()); params.addFilterQuery("onSale:T"); if (StringUtils.isNotBlank(productSolrQuery.getFatherCategoryId())) { params.addFilterQuery("fatherCategoryId:" + productSolrQuery.getFatherCategoryId()); } if (StringUtils.isNotBlank(productSolrQuery.getCategoryId())) { params.addFilterQuery("categoryId:" + productSolrQuery.getCategoryId()); } //排序 params.addSort(productSolrQuery.getSortFiled(), productSolrQuery.getSort()); //分页 params.setStart(productSolrQuery.getPage()); params.setRows(productSolrQuery.getPageSize()); QueryResponse queryResponse = solrClient.query("mall_product", params); List&lt;ProductSolrEntity&gt; beans = queryResponse.getBeans(ProductSolrEntity.class); return beans; } catch (Exception e) { e.printStackTrace(); } return null; } @Override public List&lt;String&gt; suggest(String name) { try { SolrQuery query = new SolrQuery(); // 请求到suggest中 query.set("qt", "/suggest"); // 查询的词 query.set("spellcheck.q", name); // 返回数量 query.set("spellcheck.count", "10"); QueryResponse rsp = solrClient.query("mall_product", query); // 上面取结果的代码 // 获取拼写检查的结果集 List&lt;String&gt; list = new ArrayList&lt;&gt;(); SpellCheckResponse re = rsp.getSpellCheckResponse(); if (re != null) { for (SpellCheckResponse.Suggestion s : re.getSuggestions()) { // 获取所有 的检索词 List&lt;String&gt; alternatives = s.getAlternatives(); list.addAll(alternatives); } } return list; } catch (Exception e) { e.printStackTrace(); } return new ArrayList&lt;&gt;(); } }]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[客服系统一]]></title>
    <url>%2F2018%2F10%2F12%2F%E5%AE%A2%E6%9C%8D%E7%B3%BB%E7%BB%9F%E4%B8%80%2F</url>
    <content type="text"><![CDATA[一、技术栈选择Netty使用netty做服务器Socket通信框架。 MongoDB使用MongoDB做用户的会话消息存储 二、Netty介绍什么是Netty？ Netty 是一个利用 Java 的高级网络的能力，隐藏其背后的复杂性而提供一个易于使用的 API 的客户端/服务器框架。Netty 是一个广泛使用的 Java 网络编程框架,Netty 在 2011 年获得了Duke’s Choice Award。它活跃和成长于用户社区，像大型公司 Facebook 和 Instagram 以及流行 开源项目如 Infinispan, HornetQ, Vert.x, Apache Cassandra 和 Elasticsearch 等，都利用其强大的对于网络抽象的核心代码。 为什么Netty受欢迎？并发高Netty是一款基于NIO（Nonblocking I/O，非阻塞IO）开发的网络通信框架，对比于BIO（Blocking I/O，阻塞IO），他的并发性能得到了很大提高，两张图让你了解BIO和NIO的区别： 从这两图可以看出，NIO的单线程能处理连接的数量比BIO要高出很多，而为什么单线程能处理更多的连接呢？原因就是图二中出现的Selector。当一个连接建立之后，他有两个步骤要做，第一步是接收完客户端发过来的全部数据，第二步是服务端处理完请求业务之后返回response给客户端。NIO和BIO的区别主要是在第一步。在BIO中，等待客户端发数据这个过程是阻塞的，这样就造成了一个线程只能处理一个请求的情况，而机器能支持的最大线程数是有限的，这就是为什么BIO不能支持高并发的原因。而NIO中，当一个Socket建立好之后，Thread并不会阻塞去接受这个Socket，而是将这个请求交给Selector，Selector会不断的去遍历所有的Socket，一旦有一个Socket建立完成，他会通知Thread，然后Thread处理完数据再返回给客户端——这个过程是阻塞的，这样就能让一个Thread处理更多的请求了。下面两张图是基于BIO的处理流程和netty的处理流程，辅助你理解两种方式的差别： 除了BIO和NIO之外，还有一些其他的IO模型，下面这张图就表示了五种IO模型的处理流程： BIO，同步阻塞IO，阻塞整个步骤，如果连接少，他的延迟是最低的，因为一个线程只处理一个连接，适用于少连接且延迟低的场景，比如说数据库连接。 NIO，同步非阻塞IO，阻塞业务处理但不阻塞数据接收，适用于高并发且处理简单的场景，比如聊天软件。 多路复用IO，他的两个步骤处理是分开的，也就是说，一个连接可能他的数据接收是线程a完成的，数据处理是线程b完成的，他比BIO能处理更多请求，但是比不上NIO，但是他的处理性能又比BIO更差，因为一个连接他需要两次system call，而BIO只需要一次，所以这种IO模型应用的不多。 信号驱动IO，这种IO模型主要用在嵌入式开发，不参与讨论。 异步IO，他的数据请求和数据处理都是异步的，数据请求一次返回一次，适用于长连接的业务场景。 以上摘自Linux IO模式及 select、poll、epoll详解 传输快Netty的传输快其实也是依赖了NIO的一个特性——零拷贝。我们知道，Java的内存有堆内存、栈内存和字符串常量池等等，其中堆内存是占用内存空间最大的一块，也是Java对象存放的地方，一般我们的数据如果需要从IO读取到堆内存，中间需要经过Socket缓冲区，也就是说一个数据会被拷贝两次才能到达他的的终点，如果数据量大，就会造成不必要的资源浪费。Netty针对这种情况，使用了NIO中的另一大特性——零拷贝，当他需要接收数据的时候，他会在堆内存之外开辟一块内存，数据就直接从IO读到了那块内存中去，在netty里面通过ByteBuf可以直接对这些数据进行直接操作，从而加快了传输速度。下两图就介绍了两种拷贝方式的区别，摘自摘自Linux 中的零拷贝技术，第 1 部分 上文介绍的ByteBuf是Netty的一个重要概念，他是netty数据处理的容器，也是Netty封装好的一个重要体现，将在下一部分做详细介绍。 封装好要说Netty为什么封装好，这种用文字是说不清的，直接上代码： 阻塞I/O 1234567891011121314151617181920212223242526272829303132333435public class PlainOioServer &#123; public void serve(int port) throws IOException &#123; final ServerSocket socket = new ServerSocket(port); //1 try &#123; for (;;) &#123; final Socket clientSocket = socket.accept(); //2 System.out.println("Accepted connection from " + clientSocket); new Thread(new Runnable() &#123; //3 @Override public void run() &#123; OutputStream out; try &#123; out = clientSocket.getOutputStream(); out.write("Hi!\r\n".getBytes(Charset.forName("UTF-8"))); //4 out.flush(); clientSocket.close(); //5 &#125; catch (IOException e) &#123; e.printStackTrace(); try &#123; clientSocket.close(); &#125; catch (IOException ex) &#123; // ignore on close &#125; &#125; &#125; &#125;).start(); //6 &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 非阻塞IO 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class PlainNioServer &#123; public void serve(int port) throws IOException &#123; ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); ServerSocket ss = serverChannel.socket(); InetSocketAddress address = new InetSocketAddress(port); ss.bind(address); //1 Selector selector = Selector.open(); //2 serverChannel.register(selector, SelectionKey.OP_ACCEPT); //3 final ByteBuffer msg = ByteBuffer.wrap("Hi!\r\n".getBytes()); for (;;) &#123; try &#123; selector.select(); //4 &#125; catch (IOException ex) &#123; ex.printStackTrace(); // handle exception break; &#125; Set&lt;SelectionKey&gt; readyKeys = selector.selectedKeys(); //5 Iterator&lt;SelectionKey&gt; iterator = readyKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); try &#123; if (key.isAcceptable()) &#123; //6 ServerSocketChannel server = (ServerSocketChannel)key.channel(); SocketChannel client = server.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_WRITE | SelectionKey.OP_READ, msg.duplicate()); //7 System.out.println( "Accepted connection from " + client); &#125; if (key.isWritable()) &#123; //8 SocketChannel client = (SocketChannel)key.channel(); ByteBuffer buffer = (ByteBuffer)key.attachment(); while (buffer.hasRemaining()) &#123; if (client.write(buffer) == 0) &#123; //9 break; &#125; &#125; client.close(); //10 &#125; &#125; catch (IOException ex) &#123; key.cancel(); try &#123; key.channel().close(); &#125; catch (IOException cex) &#123; // 在关闭时忽略 &#125; &#125; &#125; &#125; &#125;&#125; Netty 12345678910111213141516171819202122232425262728293031public class NettyOioServer &#123; public void server(int port) throws Exception &#123; final ByteBuf buf = Unpooled.unreleasableBuffer( Unpooled.copiedBuffer("Hi!\r\n", Charset.forName("UTF-8"))); EventLoopGroup group = new OioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); //1 b.group(group) //2 .channel(OioServerSocketChannel.class) .localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;//3 @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; //4 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.writeAndFlush(buf.duplicate()).addListener(ChannelFutureListener.CLOSE);//5 &#125; &#125;); &#125; &#125;); ChannelFuture f = b.bind().sync(); //6 f.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully().sync(); //7 &#125; &#125;&#125; 从代码量上来看，Netty就已经秒杀传统Socket编程了，但是这一部分博大精深，仅仅贴几个代码岂能说明问题，在这里给大家介绍一下Netty的一些重要概念，让大家更理解Netty。 Channel数据传输流，与channel相关的概念有以下四个，上一张图让你了解netty里面的Channel。 Channel，表示一个连接，可以理解为每一个请求，就是一个Channel。 ChannelHandler，核心处理业务就在这里，用于处理业务请求。 ChannelHandlerContext，用于传输业务数据。 ChannelPipeline，用于保存处理过程需要用到的ChannelHandler和ChannelHandlerContext. ByteBufByteBuf是一个存储字节的容器，最大特点就是使用方便，它既有自己的读索引和写索引，方便你对整段字节缓存进行读写，也支持get/set，方便你对其中每一个字节进行读写，他的数据结构如下图所示：他有三种使用模式： Heap Buffer 堆缓冲区堆缓冲区是ByteBuf最常用的模式，他将数据存储在堆空间。 Direct Buffer 直接缓冲区直接缓冲区是ByteBuf的另外一种常用模式，他的内存分配都不发生在堆，jdk1.4引入的nio的ByteBuffer类允许jvm通过本地方法调用分配内存，这样做有两个好处 通过免去中间交换的内存拷贝, 提升IO处理速度; 直接缓冲区的内容可以驻留在垃圾回收扫描的堆区以外。 DirectBuffer 在 -XX:MaxDirectMemorySize=xxM大小限制下, 使用 Heap 之外的内存, GC对此”无能为力”,也就意味着规避了在高负载下频繁的GC过程对应用线程的中断影响. Composite Buffer 复合缓冲区复合缓冲区相当于多个不同ByteBuf的视图，这是netty提供的，jdk不提供这样的功能。除此之外，他还提供一大堆api方便你使用，在这里我就不一一列出了，具体参见ByteBuf字节缓存。 CodecNetty中的编码/解码器，通过他你能完成字节与pojo、pojo与pojo的相互转换，从而达到自定义协议的目的。在Netty里面最有名的就是HttpRequestDecoder和HttpResponseEncoder了。 三、MongoDB介绍简介MongoDB是用C++语言编写的非关系型数据库。特点是高性能、易部署、易使用，存储数据十分方便，主要特性有： 面向集合存储，易于存储对象类型的数据 模式自由 支持动态查询 支持完全索引，包含内部对象 支持复制和故障恢复 使用高效的二进制数据存储，包括大型对象 文件存储格式为BSON(一种JSON的扩展) MongoDB和关系数据库的对比 对比项 mongoDB mysql oracle 表 集合 二维表table 表的一行数据 文档document 一条记录recoder 表字段 键key 字段filed 字段值 值value 值value 主外键 无 PK FK 灵活度扩展性 极高 差 MongoDB基本概念 文档(document)是MongoDB中数据的基本单元，非常类似于关系型数据库系统中的行(但是比行要复杂的多)。 集合(collection)就是一组文档，如果说MongoDB中的文档类似于关系型数据库中的行，那么集合就如同表。 MongoDB的单个计算机可以容纳多个独立的数据库，每一个数据库都有自己的集合和权限。 MongoDB自带简洁但功能强大的JavaScript shell，这个工具对于管理MongoDB实例和操作数据作用非常大。 每一个文档都有一个特殊的键”_id”,它在文档所处的集合中是唯一的，相当于关系数据库中的表的主键。 MongoDB数据类型 数据类型 描述 举例 null 表示空值或者未定义的对象 {“x”:null} 布尔值 真或者假：true或者false {“x”:true} 32位整数 32位整数。shell是不支持该类型的，shell中默认会转换成64位浮点数 64位整数 64位整数。shell是不支持该类型的，shell中默认会转换成64位浮点数 64位浮点数 64位浮点数。shell中的数字就是这一种类型 {“x”：3.14，”y”：3} 字符串 UTF-8字符串 {“foo”:”bar”} 符号 shell不支持，shell会将数据库中的符号类型的数据自动转换成字符串 对象id 文档的12字节的唯一id {“id”: ObjectId()} 日期 从标准纪元开始的毫秒数 {“date”:new Date()} 正则表达式 文档中可以包含正则表达式，遵循JavaScript的语法 {“foo”:/foobar/i} 代码 文档中可以包含JavaScript代码 {“x”：function() {}} 未定义 undefined {“x”：undefined} 数组 值的集合或者列表 {“arr”: [“a”,”b”]} 内嵌文档 文档可以作为文档中某个key的value {“x”:{“foo”:”bar”}}]]></content>
      <categories>
        <category>客服系统</category>
      </categories>
      <tags>
        <tag>im</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极光推送的配置与使用]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9E%81%E5%85%89%E6%8E%A8%E9%80%81%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一、进入极光官网创建自己的应用 进入极光推送官网注册账号 登录之后进入如下页面 创建应用包名和图标随便写记住你的AppKey 和Master Secret 后面会用到 进入推送设置 设置一个安卓的应用下载到自己手机,配置一个别名 二、安装 maven方式将下边的依赖条件放到你项目的 maven pom.xml 文件里。 12345&lt;dependency&gt; &lt;groupId&gt;cn.jpush.api&lt;/groupId&gt; &lt;artifactId&gt;jpush-client&lt;/artifactId&gt; &lt;version&gt;3.3.7&lt;/version&gt;&lt;/dependency&gt; jar 包方式请到 Release页面下载相应版本的发布包。 依赖包 slf4j / log4j (Logger) gson(Google JSON Utils) 其中 slf4j 可以与 logback, log4j, commons-logging 等日志框架一起工作，可根据你的需要配置使用。 如果使用 Maven 构建项目，则需要在你的项目 pom.xml 里增加： 123456789101112131415161718192021222324252627282930313233&lt;dependency&gt; &lt;groupId&gt;cn.jpush.api&lt;/groupId&gt; &lt;artifactId&gt;jiguang-common&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.6.Final&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;!-- For log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; 如果不使用 Maven 构建项目，则项目 libs/ 目录下有依赖的 jar 可复制到你的项目里去。 三、构建推送对象二话不说先上代码1234567891011121314151617181920212223242526272829public static PushPayload buildPushObject_android_ios_alias_alert(String alias, String alert, String type) &#123; return PushPayload.newBuilder() //设置推送平台 安卓和ios .setPlatform(Platform.android_ios()) //设置推送目标，别名是alias的设备 .setAudience(Audience.alias(alias)) //设置通知内容 .setNotification(Notification.newBuilder() .addPlatformNotification(AndroidNotification.newBuilder() .addExtra("type", type) .setAlert(alert) .build()) .addPlatformNotification(IosNotification.newBuilder() .addExtra("type", type) .setAlert(alert) .build()) .build()) //设置推送环境 .setOptions(Options.newBuilder() .setApnsProduction(false)//true-推送生产环境 false-推送开发环境（测试使用参数） .setTimeToLive(3600)//消息在JPush服务器的失效时间（测试使用参数） .build()) //设置推送内容 .setMessage(Message.newBuilder() .setMsgContent(alert) .addExtra("type", type) .build()) .build(); &#125; 四、极光推送方法12345678910111213141516171819public static PushResult push(String alias, String alert, String type) &#123; ClientConfig clientConfig = ClientConfig.getInstance(); //masterSecret和appKey 分别填上自己申请的 JPushClient jpushClient = new JPushClient(masterSecret, appKey, null, clientConfig); PushPayload payload = buildPushObject_android_ios_alias_alert(alias, alert, type); try &#123; return jpushClient.sendPush(payload); &#125; catch (APIConnectionException e) &#123; log.error("Connection error. Should retry later. ", e); return null; &#125; catch (APIRequestException e) &#123; log.error("Error response from JPush server. Should review and fix it. ", e); log.info("HTTP Status: " + e.getStatus()); log.info("Error Code: " + e.getErrorCode()); log.info("Error Message: " + e.getErrorMessage()); log.info("Msg ID: " + e.getMsgId()); return null; &#125; &#125; 五、测试随便写个测试的推送方法12345678910public static void main(String[] args) &#123; String alias = "****";//声明别名 之前在你手机设置的别名 log.info("对别名" + alias + "的用户推送信息"); PushResult result = push(String.valueOf(alias), ALERT, "***"); if (result != null &amp;&amp; result.isResultOK()) &#123; log.info("针对别名" + alias + "的信息推送成功！"); &#125; else &#123; log.info("针对别名" + alias + "的信息推送失败！"); &#125; &#125; 出现这个说明推送成功了 手机也会收到你推送的消息 六、相关异常的codeHTTP 返回码为 200 时，是业务相关的错误。 错误码 错误描述 0 调用成功 10 系统内部错误 1001 只支持 HTTP Post 方法，不支持 Get 方法 1002 缺少了必须的参数 1003 参数值不合法 1004 verification_code 验证失败 1005 消息体太大 1007 receiver_value 参数 非法 1008 appkey参数非法 1010 msg_content 不合法 1011 没有满足条件的推送目标 1012 iOS 不支持推送自定义消息。只有 Android 支持推送自定义消息。 1013 content-type 只支持 application/x-www-form-urlencoded 1014 消息内容包含敏感词汇。 1030 内部服务超时。稍后重试。 返回 1011 时：如果群发：则此应用还没有一个客户端用户注册。请检查 SDK 集成是否正常。如果是推送给某别名或者标签：则此别名或者标签还没有在任何客户端 SDK 提交设置成功。]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建hexo博客]]></title>
    <url>%2F2018%2F09%2F27%2F%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一、安装Nodejs下载地址: https://nodejs.org/ 二、安装Git for windows下载地址: https://git-for-windows.github.io/一路Next安装就好 三、安装Hexo打开Git Bash，执行命令: npm install hexo-cli -g 如果不行就先执行: npm --registry http://registry.cnpmjs.org info underscore 再执行: npm install hexo-cli -g 然后执行: hexo -v 如果安装成功的话会出现如下图: 四、新建一个blog项目文件夹比如：在D盘新建一 个D：/myblog放置blog项目。点击鼠标右键，选择Git Bash Here。 然后依次执行以下命令: 1234hexo initnpm install hexo ghexo s 在本地浏览器上输入地址:http://localhost:4000/ 就可以看到如下图画面了 五、配置Git 登录github创建仓库创建一个repo，名称为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用哦 配置本地github账户信息打开gitbash 12git config --global user.name &quot;&lt;你的name&gt;&quot;git config --global user.email &quot;&lt;你的email&gt;&quot; 创建ssh在gitbash中输入:ssh-keygen -t rsa -C &quot;youremail@example.com 按提示找id_rsa.pub文件，可以用记事本打开，复制全部内容。在浏览器中打开 https://github.com ，登录并打开settings，在SSH and GPG keys下New SSH Key，title随便填写，key就粘贴复制id_rsa.pub文件的内容。在gitbash中执行以下命令验证是否添加成功:ssh -T git@github.com 六、更改hexo配置 用编辑器打开你的blog项目，修改_config.yml文件的一些配置(冒号之后都是有一个半角空格的): 1234deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: master 回到gitbash中，进入你的blog目录，分别执行以下命令: 123hexo cleanhexo generatehexo server 注：hexo 3.0把服务器独立成个别模块，需要单独安装:npm i hexo-server 打开浏览器输入：http://localhost:4000 接着你就可以遇见天使的微笑了~ 七、上传到github 先安装一波：npm install hexo-deployer-git --save（这样才能将你写好的文章部署到github服务器上并让别人浏览到） 执行命令(建议每次都按照如下步骤部署):123hexo cleanhexo generatehexo deploy 注意deploy的过程中要输入你的username及passward，最后出现Deploy done:git 说明上传成功了最后浏览器输入http://yourgithubname.github.io就能看到你的博客了！ 八、绑定个人域名 第一步购买域名：随便在哪个网站买一个就好了，我是在阿里云购买的jingxu.top,六块钱一年不贵。 第二步添加CNAME：在项目的source文件夹下新建一个名为CNAME的文件，在里面添加你购买的域名，比如我添加的是jingxu.top，只能添加一个。 到DNS中添加一条记录： 接着再次部署一下，用你购买的域名打开，就可以看到你的博客啦~ 如果没有的话 在setting 往下拉 会看见如果没有Custom domain可能是你CNAME名字写错了，全部大写CNAME 不是 GNAME]]></content>
      <categories>
        <category>hexo博客</category>
      </categories>
      <tags>
        <tag>博客环境搭建</tag>
      </tags>
  </entry>
</search>
